{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15413324-97d9-44e2-8164-0934da006e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import label_studio_sdk\n",
    "import logging\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "from label_studio_ml.model import LabelStudioMLBase\n",
    "from label_studio_ml.response import ModelResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae42211-e316-4c7d-bdd0-d176f48a649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline, Pipeline\n",
    "from itertools import groupby\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import Dataset, ClassLabel, Value, Sequence, Features\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f891095a-4d17-44c7-a9b6-e69743efd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "_model: Optional[Pipeline] = None\n",
    "MODEL_DIR = os.getenv('MODEL_DIR', './results')\n",
    "BASELINE_MODEL_NAME = os.getenv('BASELINE_MODEL_NAME', 'Babelscape/wikineural-multilingual-ner')\n",
    "BASELINE_MODEL_NAME = os.getenv('BASELINE_MODEL_NAME', 'DmitryPogrebnoy/distilbert-base-russian-cased')\n",
    "FINETUNED_MODEL_NAME = os.getenv('FINETUNED_MODEL_NAME', 'finetuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04d460d-277b-42bb-8cfe-13b291911d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_config = '''<View style=\"display:flex;align-items:start;gap:8px;flex-direction:row\">\n",
    "                   <Text name=\"text\" value=\"$clearText\" granularity=\"word\"/>\n",
    "                   <Labels name=\"label\" toName=\"text\" showInline=\"false\">\n",
    "                    <Label value=\"DIR\" background=\"#4824f9\"/>\n",
    "                    <Label value=\"SLD\" background=\"#00ff1e\"/>\n",
    "                    <Label value=\"WP\" background=\"#ff0000\"/>\n",
    "                  \t<Label value=\"LOC\" background=\"#57fff4\"/>\n",
    "                    <Label value=\"UNIT\" background=\"green\"/>\n",
    "                    <Label value=\"COUNT\" background=\"#000000\"/>\n",
    "                    <Label value=\"FREE\" background=\"#0008ff\"/>\n",
    "                    <Label value=\"LOST\" background=\"#ff0000\"/>\n",
    "                    <Label value=\"CAPT\" background=\"#ffbb00\"/>\n",
    "                  </Labels>\n",
    "                </View> '''\n",
    "project_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4eb408c-f91a-42ca-b550-3ab4f7cac0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_model():\n",
    "    global _model\n",
    "    _model = None\n",
    "    try:\n",
    "        chk_path = str(pathlib.Path(MODEL_DIR) / FINETUNED_MODEL_NAME)\n",
    "        logger.info(f\"Loading finetuned model from {chk_path}\")\n",
    "        _model = pipeline(\"ner\", model=chk_path, tokenizer=chk_path)\n",
    "    except:\n",
    "        # if finetuned model is not available, use the baseline model with the original labels\n",
    "        logger.info(f\"Loading baseline model {BASELINE_MODEL_NAME}\")\n",
    "        _model = pipeline(\"ner\", model=BASELINE_MODEL_NAME, tokenizer=BASELINE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fe6de4-39e7-4345-b7f7-77d4f89c6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18f9fd6-3d69-4f9c-9932-342833cbb7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingFaceNER(LabelStudioMLBase):\n",
    "    \"\"\"Custom ML Backend model\n",
    "    \"\"\"\n",
    "    LABEL_STUDIO_HOST = os.getenv('LABEL_STUDIO_HOST', 'http://localhost:8080')\n",
    "    LABEL_STUDIO_API_KEY = os.getenv('LABEL_STUDIO_API_KEY', 'c35a2f5689358d1e9d7522309643ba5b9cfca062')\n",
    "    START_TRAINING_EACH_N_UPDATES = int(os.getenv('START_TRAINING_EACH_N_UPDATES', 10))\n",
    "    LEARNING_RATE = float(os.getenv('LEARNING_RATE', 1e-3))\n",
    "    NUM_TRAIN_EPOCHS = int(os.getenv('NUM_TRAIN_EPOCHS', 10))\n",
    "    WEIGHT_DECAY = float(os.getenv('WEIGHT_DECAY', 0.01))\n",
    "\n",
    "    def get_labels(self):\n",
    "        li = self.label_interface\n",
    "        from_name, _, _ = li.get_first_tag_occurence('Labels', 'Text')\n",
    "        tag = li.get_tag(from_name)\n",
    "        return tag.labels\n",
    "    \n",
    "    def _get_tasks(self, project_id):\n",
    "        # download annotated tasks from Label Studio\n",
    "        ls = label_studio_sdk.Client(self.LABEL_STUDIO_HOST, self.LABEL_STUDIO_API_KEY)\n",
    "        project = ls.get_project(id=project_id)\n",
    "        tasks = project.get_labeled_tasks()\n",
    "        return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991e79a-8e32-4cbc-a63d-f0c2f142af3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51292cd-0c1f-4499-a781-4299c427d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner =  HuggingFaceNER (project_id = project_id, label_config = label_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90945fee-28e5-40ca-8272-f9132078473a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIR', 'SLD', 'WP', 'LOC', 'UNIT', 'COUNT', 'FREE', 'LOST', 'CAPT']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba34d927-ed24-4e59-b70e-c5aa8f457880",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ner._get_tasks(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e0cad7-b55c-43f1-bcc3-721cb02f7eef",
   "metadata": {},
   "outputs": [],
   "source": [
    " # we need to convert Label Studio NER annotations to hugingface NER format in datasets\n",
    "        # for example:\n",
    "        # {'id': '0',\n",
    "        #  'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        #  'tokens': ['@paulwalk', 'It', \"'s\", 'the', 'view', 'from', 'where', 'I', \"'m\", 'living', 'for', 'two', 'weeks', '.', 'Empire', 'State', 'Building', '=', 'ESB', '.', 'Pretty', 'bad', 'storm', 'here', 'last', 'evening', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33632184-945e-4bcb-8e6e-fe9287edadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = []\n",
    "from_name, to_name, value = ner.label_interface.get_first_tag_occurence('Labels', 'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a03889-f075-4129-9c3b-1e228688ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrey.NOUT\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASELINE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6380e16-9e86-4383-bc34-d3417e8ea9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label = 'O'\n",
    "label_to_id = {no_label: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5deaa4d5-cdf8-47d7-9639-4fc3f55573b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91459aeb-ab96-4f1e-a2c1-fac9db8183fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09176d4-ef4c-47dd-8541-106631f5aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = task['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73747a5b-3f97-4a97-9a7c-a268d26c4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d18c8006-69c2-44ee-a0f1-94156c052681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# фильтруем результат - что бы была только разметака (value)\n",
    "list_values = list(filter(lambda r: r['type'] == 'labels', annotation['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d6b9b8-fcaa-41d1-9edf-b3b34b460c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метка, начало, конец.\n",
    "spans = [{'label': r['value']['labels'][0], 'start': r['value']['start'], 'end': r['value']['end']} for r in list_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fd7f0ee-3a4d-4c77-96c9-d348758a6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a822e8e-ec31-4279-9874-4886e9a76c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = sorted(spans, key=lambda x: x['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fee10c-cb94-4e01-bc74-76923c809f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем текст\n",
    "text = ner.preload_task_data(task, task['data'][value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f1acfcb-183b-4966-8923-07b3f86360c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef313cde-cd06-4580-8f04-33eed51a3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    " # insert tokenizer.pad_token to the unlabeled chunks of the text in-between the labeled spans, as well as to the beginning and end of the text\n",
    "last_end = 0\n",
    "all_spans = []\n",
    "for span in spans:\n",
    "    if last_end < span['start']:\n",
    "        all_spans.append({'label': no_label, 'start': last_end, 'end': span['start']})\n",
    "    all_spans.append(span)\n",
    "    last_end = span['end']\n",
    "if last_end < len(text):\n",
    "    all_spans.append({'label': no_label, 'start': last_end, 'end': len(text)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f14e59-2426-46c6-a8f7-15043e19e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # now tokenize chunks separately and add them to the dataset\n",
    "item = {'id': task['id'], 'tokens': [], 'ner_tags': []}\n",
    "for span in all_spans:\n",
    "    tokens = tokenizer.tokenize(text[span['start']:span['end']])\n",
    "    item['tokens'].extend(tokens)\n",
    "    if span['label'] == no_label:\n",
    "        item['ner_tags'].extend([label_to_id[no_label]] * len(tokens))\n",
    "    else:\n",
    "        label = 'B-' + span['label']\n",
    "        if label not in label_to_id:\n",
    "            label_to_id[label] = len(label_to_id)\n",
    "        item['ner_tags'].append(label_to_id[label])\n",
    "        if len(tokens) > 1:\n",
    "            label = 'I-' + span['label']\n",
    "            if label not in label_to_id:\n",
    "                label_to_id[label] = len(label_to_id)\n",
    "            item['ner_tags'].extend([label_to_id[label] for _ in range(1, len(tokens))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4672cbf-f738-4d33-b4a8-61f20ca1e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2f1df46-1181-4a0b-be45-f228eae3aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "ds_raw = []\n",
    "for task in tasks:\n",
    "    for annotation in task['annotations']:\n",
    "        if not annotation.get('result'):\n",
    "            continue\n",
    "        # фильтруем результат - что бы была только разметака (value)\n",
    "        list_values = list(filter(lambda r: r['type'] == 'labels', annotation['result']))\n",
    "        spans = [{'label': r['value']['labels'][0], 'start': r['value']['start'], 'end': r['value']['end']} for r in list_values]\n",
    "        spans = sorted(spans, key=lambda x: x['start'])\n",
    "        text = ner.preload_task_data(task, task['data'][value])\n",
    "        #text = text[:512]\n",
    "        # insert tokenizer.pad_token to the unlabeled chunks of the text in-between the labeled spans, as well as to the beginning and end of the text\n",
    "        last_end = 0\n",
    "        all_spans = []\n",
    "        for span in spans:\n",
    "            if last_end < span['start']:\n",
    "                all_spans.append({'label': no_label, 'start': last_end, 'end': span['start']})\n",
    "            all_spans.append(span)\n",
    "            last_end = span['end']\n",
    "        if last_end < len(text):\n",
    "            all_spans.append({'label': no_label, 'start': last_end, 'end': len(text)})\n",
    "    \n",
    "        # now tokenize chunks separately and add them to the dataset\n",
    "        item = {'id': task['id'], 'tokens': [], 'ner_tags': []}\n",
    "        for span in all_spans:\n",
    "            tokens = tokenizer.tokenize(text[span['start']:span['end']])\n",
    "            tokens_ids = tokenizer.encode(text[span['start']:span['end']], add_special_tokens=False)\n",
    "            item['tokens'].extend(tokens)\n",
    "            if span['label'] == no_label:\n",
    "                item['ner_tags'].extend([label_to_id[no_label]] * len(tokens))\n",
    "            else:\n",
    "                label = 'B-' + span['label']\n",
    "                if label not in label_to_id:\n",
    "                    label_to_id[label] = len(label_to_id)\n",
    "                item['ner_tags'].append(label_to_id[label])\n",
    "                if len(tokens) > 1:\n",
    "                    label = 'I-' + span['label']\n",
    "                    if label not in label_to_id:\n",
    "                        label_to_id[label] = len(label_to_id)\n",
    "                    item['ner_tags'].extend([label_to_id[label] for _ in range(1, len(tokens))])\n",
    "        ds_raw.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5b2386f-1104-4749-940a-8d18be354f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_raw[0][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95cf3d49-4fe3-4fa1-9ccb-9936911c09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to huggingface dataset\n",
    "# Define the features of your dataset\n",
    "features = Features({\n",
    "    'id': Value('string'),\n",
    "    'tokens': Sequence(Value('string')),\n",
    "    'ner_tags': Sequence(ClassLabel(names=list(label_to_id.keys())))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "330ede6f-396f-480b-8eda-8a9a519cd328",
   "metadata": {},
   "outputs": [],
   "source": [
    " def tokenize_and_align_labels( examples, tokenizer):\n",
    "    \"\"\"\n",
    "    From example https://huggingface.co/docs/transformers/en/tasks/token_classification#preprocess\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa59f3c5-309b-4ab6-bf37-60ae5746f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_list(ds_raw, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e8f4cb7-655b-4933-9340-42aac87e0755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf30183d2c174fd2b9d874bf099b564d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = hf_dataset.map(partial(tokenize_and_align_labels, tokenizer=tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4528d28-c3cc-4852-b050-f5af9f346fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 164\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2d2b413-a7c6-4a14-ae01-ea07b6f20284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_dataset[0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "390f3a17-6f21-4869-8c50-f56e5c3edc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46c88d90-8f10-4ae3-b02c-f29206e396bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForTokenClassification(tokenizer=DistilBertTokenizerFast(name_or_path='DmitryPogrebnoy/distilbert-base-russian-cased', vocab_size=13982, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceb9c092-7566-4dc3-8e8c-6127b53927a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-DIR',\n",
       " 2: 'I-DIR',\n",
       " 3: 'B-LOC',\n",
       " 4: 'I-LOC',\n",
       " 5: 'B-COUNT',\n",
       " 6: 'B-SLD',\n",
       " 7: 'I-SLD',\n",
       " 8: 'B-WP',\n",
       " 9: 'I-WP',\n",
       " 10: 'B-UNIT',\n",
       " 11: 'I-UNIT',\n",
       " 12: 'I-COUNT',\n",
       " 13: 'B-FREE',\n",
       " 14: 'I-FREE',\n",
       " 15: 'B-CAPT',\n",
       " 16: 'I-CAPT'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6706be24-0ece-484a-b4c7-f0c4c7568151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-DIR': 1,\n",
       " 'I-DIR': 2,\n",
       " 'B-LOC': 3,\n",
       " 'I-LOC': 4,\n",
       " 'B-COUNT': 5,\n",
       " 'B-SLD': 6,\n",
       " 'I-SLD': 7,\n",
       " 'B-WP': 8,\n",
       " 'I-WP': 9,\n",
       " 'B-UNIT': 10,\n",
       " 'I-UNIT': 11,\n",
       " 'I-COUNT': 12,\n",
       " 'B-FREE': 13,\n",
       " 'I-FREE': 14,\n",
       " 'B-CAPT': 15,\n",
       " 'I-CAPT': 16}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c5bc997-4007-4d67-a338-5428e836b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at DmitryPogrebnoy/distilbert-base-russian-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "            BASELINE_MODEL_NAME, num_labels=len(id_to_label),\n",
    "            id2label=id_to_label, label2id=label_to_id)\n",
    "\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\n",
    "#             BASELINE_MODEL_NAME, \n",
    "#             id2label=id_to_label, label2id=label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00f1b471-4adc-431b-ad5f-bd231a8a991c",
   "metadata": {},
   "outputs": [],
   "source": [
    " training_args = TrainingArguments(\n",
    "    output_dir=str(pathlib.Path(MODEL_DIR) / FINETUNED_MODEL_NAME),\n",
    "    learning_rate=ner.LEARNING_RATE,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=ner.NUM_TRAIN_EPOCHS,\n",
    "    weight_decay=ner.WEIGHT_DECAY,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "801b7854-6de6-46aa-82f0-ca0f180eea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers==4.39.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11b9dff8-d0e6-448f-8d86-7e3a2a75cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install accelerate==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "389b4f5f-d20b-4ef2-86a9-46bb79cfc9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 03:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.005733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.004756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.006070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.013386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.014303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.005023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.001972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=210, training_loss=1.0811178298223587, metrics={'train_runtime': 215.3412, 'train_samples_per_second': 7.616, 'train_steps_per_second': 0.975, 'total_flos': 214329198305280.0, 'train_loss': 1.0811178298223587, 'epoch': 10.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f4d3164-04ca-45ed-9b81-ab750fff3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = str(pathlib.Path(MODEL_DIR) / FINETUNED_MODEL_NAME)\n",
    "logger.info(f\"Model is trained and saved as {chk_path}\")\n",
    "trainer.save_model(chk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a60b58d0-0e3c-466f-b8a1-d10668fdef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results\\\\finetuned_model'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82651b38-2842-4329-b8b7-5b046d451788",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8269567f-1830-490f-96da-a3a1456bfa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = ner.label_interface\n",
    "from_name, to_name, value = li.get_first_tag_occurence('Labels', 'Text')\n",
    "texts = [ner.preload_task_data(task, task['data'][value]) for task in tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7eb32109-17f0-4354-8c3e-a6edca35932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = task['data'][value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01c938cc-41ba-4d11-b2fd-1c64a5adcae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Сводка Министерства обороны Российской Федерации о ходе проведения специальной военной операциипо состоянию на 30 июня 2024 г.Часть 2  Подразделения группировки войск Восток заняли более выгодные рубежи и нанесли поражение живой силе и технике 115-й, 123-й, 128-й бригад теробороны в районах населенных пунктов Ровнополь, Времевка, Новоукраинка и Великая Новоселка Донецкой Народной Республики. Отражена контратака штурмовой группы 123-й бригады теробороны противника.ВСУ потеряли до 130 военнослужащих, две боевые бронированные машины, семь автомобилей, 155-мм гаубицу FH-70 производства Великобритании, 155-мм гаубицу М198 производства США, две 122-мм гаубицы Д-30.Уничтожены два полевых склада боеприпасов и склад военно-технического имущества ВСУ. Подразделениями группировки войск Днепр нанесено поражение живой силе и технике 35-й бригады морской пехоты, 121-й бригады теробороны и 22-й бригады нацгвардии в районах населенных пунктов Ильинка Днепропетровской области, Золотая Балка, Ольговка и Тягинка Херсонской области.Потери противника составили до 105 военнослужащих, восемь автомобилей, две 155-мм гаубицы М777 производства США, 122-мм гаубица Д-30 и 105-мм орудие М119 производства США.Также уничтожены: станция радиоэлектронной борьбы Анклав-AD и три полевых склада боеприпасов ВСУ. Оперативно-тактической авиацией, беспилотными летательными аппаратами, ракетными войсками и артиллерией группировок войск Вооруженных Сил Российской Федерации поражен во время разгрузки железнодорожный эшелон с вооружением, военной техникой и личным составом 117-й механизированной бригады ВСУ, а также скопления живой силы и военной техники противника в 127 районах. Средствами противовоздушной обороны сбито 72 беспилотных летательных аппарата, две управляемые ракеты большой дальности Нептун-МД, три ложные воздушные цели MALD производства США и девять реактивных снарядов HIMARS производства США. Всего с начала проведения специальной военной операции уничтожено: 616 самолетов, 276 вертолетов, 26968 беспилотных летательных аппаратов, 535 зенитных ракетных комплексов, 16463 танка и других боевых бронированных машин, 1361 боевая машина реактивных систем залпового огня, 11129 орудий полевой артиллерии и минометов, а также 23136 единиц специальной военной автомобильной техники. '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92f76c19-2fc5-484c-9016-165f12edd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = _model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb0a583b-d79a-4978-b7d5-84daece9288a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b2f6498c-f7ad-449e-aa40-96d9f732bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for prediction in model_predictions:\n",
    "    # prediction returned in the format: [{'entity': 'B-ORG', 'score': 0.999, 'index': 1, 'start': 0, 'end': 7, 'word': 'Google'}, ...]\n",
    "    # we need to group them by 'B-' and 'I-' prefixes to form entities\n",
    "    results = []\n",
    "    avg_score = 0\n",
    "    for label, group in groupby(prediction, key=lambda x: re.sub(r'^[BI]-', '', x['entity'])):\n",
    "        entities = list(group)\n",
    "        start = entities[0]['start']\n",
    "        end = entities[-1]['end']\n",
    "        score = float(sum([entity['score'] for entity in entities]) / len(entities))\n",
    "        results.append({\n",
    "            'from_name': from_name,\n",
    "            'to_name': to_name,\n",
    "            'type': 'labels',\n",
    "            'value': {\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'labels': [label]\n",
    "            },\n",
    "            'score': score\n",
    "        })\n",
    "        avg_score += score\n",
    "    if results:\n",
    "        predictions.append({\n",
    "            'result': results,\n",
    "            'score': avg_score / len(results),\n",
    "            'model_version': ner.get('model_version')\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "337cb896-911e-485c-b7ef-49cc310ac4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForTokenClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(13982, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abf5c1-3ac4-49cd-97be-c14c79650083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b9970-248f-497c-a752-9c4389a6f356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602560a-9f1c-48ff-9ec1-e152bf985521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4c71f-8999-4ea5-a12b-a91e58e0444e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ce2fa-0532-442b-91d8-cc7876b7d267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e341d1-8bd4-4df1-a59d-5d31df4c3038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "00152a3b-9690-4e0c-87d2-1bb174d2ba08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-DIR',\n",
       " 2: 'I-DIR',\n",
       " 3: 'B-LOC',\n",
       " 4: 'I-LOC',\n",
       " 5: 'B-COUNT',\n",
       " 6: 'B-SLD',\n",
       " 7: 'I-SLD',\n",
       " 8: 'B-WP',\n",
       " 9: 'I-WP',\n",
       " 10: 'B-UNIT',\n",
       " 11: 'I-UNIT',\n",
       " 12: 'I-COUNT',\n",
       " 13: 'B-FREE',\n",
       " 14: 'I-FREE',\n",
       " 15: 'B-CAPT',\n",
       " 16: 'I-CAPT'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93b650-030a-4a4f-b901-9fc2df41b66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01283c70-e911-4751-b58b-10a78fbebefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f5f11-476f-4126-8e75-0f6d185f58f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4eeb68-98d8-4907-8414-1fa7eb70cb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a9f10-9c47-4ce0-8bf2-ecc42b48e0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d8cc7-37a6-4d7a-8fdf-fba29147fd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d63a2d-d004-4482-b823-4931f6ae0d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa155c-aef6-4d06-b454-e33d28ae2361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7684e3d-0dfd-4cda-b7bf-f2eefc527195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-DIR': 1,\n",
       " 'I-DIR': 2,\n",
       " 'B-LOC': 3,\n",
       " 'I-LOC': 4,\n",
       " 'B-COUNT': 5,\n",
       " 'B-SLD': 6,\n",
       " 'I-SLD': 7,\n",
       " 'B-WP': 8,\n",
       " 'I-WP': 9,\n",
       " 'B-UNIT': 10,\n",
       " 'I-UNIT': 11}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41243b40-c53a-4eb4-a925-258739db894d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3ceb8-b4c4-44d0-868e-c225433a3a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b09ab-fd8b-4e6f-b365-bf0277785bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47295d04-278b-47d2-9f03-2438aefd11c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034ab7a-57ea-4cec-b822-806e73c499a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd029a-71d4-4e03-b6c0-bd0ca6fde86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067afbaa-b1e4-4b1a-92a4-8deb8c44870c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c132533-4336-4732-84ba-35e5b02f04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc5d66f8-ef92-48ef-ad91-659441092385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)\n",
    "    # for annotation in task['annotations']:\n",
    "    #     print (annannotation)\n",
    "        #if not annotation.get('result'):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b42478-b31e-4827-a1dc-9b5122bb899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72277ca0-94a8-4f33-a413-4c27c738ecb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0254cec-d0d6-43eb-aee7-e6fc0ec5f9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d8637-dc81-4d72-b16b-9d4764a1e70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859529d-c152-4e3a-ae5c-82a2f43d6148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32289cac-9661-45e3-b6b0-dcab0eec8179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b18a6-18a2-4667-b744-ac3fe599bac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e14af-8c89-4b9a-8f38-4408c5c3a857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd8d57f4-64bd-43c8-bad9-b65242095146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(\"json\", data_files=\"RMDR_ANATATION_3_MONTH.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c33b8-56e4-4059-9053-f8433cfc8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30006c-ae1e-48ff-b754-3adc69a834b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db76bcdb-539d-4f54-811d-8d56df5b34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  C:\\ProgramData\\anaconda3\\python.exe -m pip <command> [options]\n",
      "\n",
      "Commands:\n",
      "  install                     Install packages.\n",
      "  download                    Download packages.\n",
      "  uninstall                   Uninstall packages.\n",
      "  freeze                      Output installed packages in requirements format.\n",
      "  inspect                     Inspect the python environment.\n",
      "  list                        List installed packages.\n",
      "  show                        Show information about installed packages.\n",
      "  check                       Verify installed packages have compatible dependencies.\n",
      "  config                      Manage local and global configuration.\n",
      "  search                      Search PyPI for packages.\n",
      "  cache                       Inspect and manage pip's wheel cache.\n",
      "  index                       Inspect information available from package indexes.\n",
      "  wheel                       Build wheels from your requirements.\n",
      "  hash                        Compute hashes of package archives.\n",
      "  completion                  A helper command used for command completion.\n",
      "  debug                       Show information useful for debugging.\n",
      "  help                        Show help for commands.\n",
      "\n",
      "General Options:\n",
      "  -h, --help                  Show help.\n",
      "  --debug                     Let unhandled exceptions propagate outside the\n",
      "                              main subroutine, instead of logging them to\n",
      "                              stderr.\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\n",
      "                              environment variables and user configuration.\n",
      "  --require-virtualenv        Allow pip to only run in a virtual environment;\n",
      "                              exit with an error otherwise.\n",
      "  --python <python>           Run pip with the specified Python interpreter.\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\n",
      "                              used up to 3 times.\n",
      "  -V, --version               Show version and exit.\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\n",
      "                              used up to 3 times (corresponding to WARNING,\n",
      "                              ERROR, and CRITICAL logging levels).\n",
      "  --log <path>                Path to a verbose appending log.\n",
      "  --no-input                  Disable prompting for input.\n",
      "  --keyring-provider <keyring_provider>\n",
      "                              Enable the credential lookup via the keyring\n",
      "                              library if user input is allowed. Specify which\n",
      "                              mechanism to use [disabled, import, subprocess].\n",
      "                              (default: disabled)\n",
      "  --proxy <proxy>             Specify a proxy in the form\n",
      "                              scheme://[user:passwd@]proxy.server:port.\n",
      "  --retries <retries>         Maximum number of retries each connection should\n",
      "                              attempt (default 5 times).\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\n",
      "  --exists-action <action>    Default action when a path already exists:\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\n",
      "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\n",
      "                              even though it does not have valid or any HTTPS.\n",
      "  --cert <path>               Path to PEM-encoded CA certificate bundle. If\n",
      "                              provided, overrides the default. See 'SSL\n",
      "                              Certificate Verification' in pip documentation\n",
      "                              for more information.\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\n",
      "                              containing the private key and the certificate\n",
      "                              in PEM format.\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\n",
      "  --no-cache-dir              Disable the cache.\n",
      "  --disable-pip-version-check\n",
      "                              Don't periodically check PyPI to determine\n",
      "                              whether a new version of pip is available for\n",
      "                              download. Implied with --no-index.\n",
      "  --no-color                  Suppress colored output.\n",
      "  --no-python-version-warning\n",
      "                              Silence deprecation warnings for upcoming\n",
      "                              unsupported Pythons.\n",
      "  --use-feature <feature>     Enable new functionality, that may be backward\n",
      "                              incompatible.\n",
      "  --use-deprecated <feature>  Enable deprecated functionality, that will be\n",
      "                              removed in the future.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84c300ac-05b5-455d-ba76-f3bbb727cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RMDR_ANATATION_3_MONTH.json',  encoding=\"utf8\") as f:\n",
    "    messages = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce6620a7-87a6-4830-a6dc-61a8463ebe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e47f32b9-6af8-4ae8-8c83-3dd94a4a1394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d17755-9690-466e-a93f-32ff22c5bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23d214c8-1117-4a73-aee9-861879f7ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(map(lambda msg: {\"id\": msg[\"id\"], \"date\": msg[\"date\"], \"clearText\": msg[\"clearText\"], \"label\": msg[\"label\"] }, messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09681f88-7b67-49eb-9294-69038dc6c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23406da-a524-440a-96ea-fca0d4b5a5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870637f9-c9e3-4415-b692-abbf5a8f9ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5194ae8-8f47-40aa-be2f-54d6cebbf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = pd.read_json('RMDR_ANATATION_3_MONTH.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1619a9bf-4531-482d-94ba-260ec2d8ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "828dac96-cf4e-4ecc-a897-4010c9aefc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>clearText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1602</td>\n",
       "      <td>2024-06-13T13:51:35</td>\n",
       "      <td>Сводка Министерства обороны Российской Федерац...</td>\n",
       "      <td>[{'start': 259, 'end': 264, 'text': 'Север', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1586</td>\n",
       "      <td>2024-06-05T13:11:37</td>\n",
       "      <td>Сводка Министерства обороны Российской Федерац...</td>\n",
       "      <td>[{'start': 166, 'end': 172, 'text': 'Восток', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>2022-07-07T11:51:51</td>\n",
       "      <td>Сводка Министерства обороны Российской Федера...</td>\n",
       "      <td>[{'start': 272, 'end': 275, 'text': '142', 'la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1580</td>\n",
       "      <td>2024-06-02T11:55:23</td>\n",
       "      <td>Сводка Министерства обороны Российской Федерац...</td>\n",
       "      <td>[{'start': 255, 'end': 260, 'text': 'Север', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>2022-07-07T11:51:48</td>\n",
       "      <td>Сводка Министерства обороны Российской Федера...</td>\n",
       "      <td>[{'start': 474, 'end': 483, 'text': '2,5 тысяч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>865</td>\n",
       "      <td>2023-06-26T14:57:45</td>\n",
       "      <td>Сводка Министерства обороны Российской Федера...</td>\n",
       "      <td>[{'start': 264, 'end': 266, 'text': '83', 'lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1626</td>\n",
       "      <td>2024-06-24T13:12:34</td>\n",
       "      <td>Сводка Министерства обороны Российской Федерац...</td>\n",
       "      <td>[{'start': 258, 'end': 263, 'text': 'Север', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1627</td>\n",
       "      <td>2024-06-24T13:12:34</td>\n",
       "      <td>Сводка Министерства обороны Российской Федерац...</td>\n",
       "      <td>[{'start': 167, 'end': 173, 'text': 'Восток', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1639</td>\n",
       "      <td>2024-06-30T13:14:00</td>\n",
       "      <td>Сводка Министерства обороны Российской Федерац...</td>\n",
       "      <td>[{'start': 167, 'end': 173, 'text': 'Восток', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>32</td>\n",
       "      <td>2022-07-02T12:39:24</td>\n",
       "      <td>Сводка Министерства обороны Российской Федера...</td>\n",
       "      <td>[{'start': 311, 'end': 324, 'text': 'Верхнекам...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 date  \\\n",
       "0    1602  2024-06-13T13:51:35   \n",
       "1    1586  2024-06-05T13:11:37   \n",
       "2      45  2022-07-07T11:51:51   \n",
       "3    1580  2024-06-02T11:55:23   \n",
       "4      44  2022-07-07T11:51:48   \n",
       "..    ...                  ...   \n",
       "159   865  2023-06-26T14:57:45   \n",
       "160  1626  2024-06-24T13:12:34   \n",
       "161  1627  2024-06-24T13:12:34   \n",
       "162  1639  2024-06-30T13:14:00   \n",
       "163    32  2022-07-02T12:39:24   \n",
       "\n",
       "                                             clearText  \\\n",
       "0    Сводка Министерства обороны Российской Федерац...   \n",
       "1    Сводка Министерства обороны Российской Федерац...   \n",
       "2     Сводка Министерства обороны Российской Федера...   \n",
       "3    Сводка Министерства обороны Российской Федерац...   \n",
       "4     Сводка Министерства обороны Российской Федера...   \n",
       "..                                                 ...   \n",
       "159   Сводка Министерства обороны Российской Федера...   \n",
       "160  Сводка Министерства обороны Российской Федерац...   \n",
       "161  Сводка Министерства обороны Российской Федерац...   \n",
       "162  Сводка Министерства обороны Российской Федерац...   \n",
       "163   Сводка Министерства обороны Российской Федера...   \n",
       "\n",
       "                                                 label  \n",
       "0    [{'start': 259, 'end': 264, 'text': 'Север', '...  \n",
       "1    [{'start': 166, 'end': 172, 'text': 'Восток', ...  \n",
       "2    [{'start': 272, 'end': 275, 'text': '142', 'la...  \n",
       "3    [{'start': 255, 'end': 260, 'text': 'Север', '...  \n",
       "4    [{'start': 474, 'end': 483, 'text': '2,5 тысяч...  \n",
       "..                                                 ...  \n",
       "159  [{'start': 264, 'end': 266, 'text': '83', 'lab...  \n",
       "160  [{'start': 258, 'end': 263, 'text': 'Север', '...  \n",
       "161  [{'start': 167, 'end': 173, 'text': 'Восток', ...  \n",
       "162  [{'start': 167, 'end': 173, 'text': 'Восток', ...  \n",
       "163  [{'start': 311, 'end': 324, 'text': 'Верхнекам...  \n",
       "\n",
       "[164 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ab76e-f5bd-436c-ac68-b235f48aeb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
